---
title: "ADR-002: テスト戦略とカバレッジ目標"
type: "Architecture Decision Record"
adr_number: "002"
created_date: "2025-06-02"
author: "@nabekou29"
approver: "@nabekou29"
status: "accepted"
category: "process"
impact_level: "high"
---

# ADR-002: テスト戦略とカバレッジ目標

## ステータス

**現在のステータス:** 採用済み

**決定日:** 2025-06-02

**関連する決定:**

- 置き換える決定: なし
- 関連する決定: ADR-001（技術スタック選定）
- この決定により置き換えられる: 将来的に更新

---

## コンテキスト

### 背景・状況

LSPサーバーは開発者の日常的なワークフローに直接影響するため、高い品質と信頼性が求められる。また、AI支援により従来困難だった高品質テストを効率的に実現する機会がある。

**現在の状況:**

- 体系的なテスト戦略が未定義
- 品質保証の仕組みが不足
- 開発速度と品質のバランスが必要

**解決すべき問題:**

- バグが本番環境に流出するリスクの軽減
- 新機能追加時の既存機能の破綻防止
- 効率的なテスト環境の構築
- 品質指標の定量的な測定・追跡
- AI支援による高品質テストの効率的実現

### 制約条件

**技術的制約:**

- Rustエコシステムのテストツールに依存
- cargo-llvm-cov等のツールへの依存
- 非同期コードのテストが必要

**ビジネス制約:**

- 開発者1名+AIエージェントの体制
- 完璧を目指さず、重要な部分から着実に進める
- 開発速度を維持しながら品質を確保

**外部制約:**

- CI/CD環境での実行時間制限
- オープンソースプロジェクトとしてのメンテナンス性

---

## 検討した選択肢

### 選択肢A: テストトロフィー・AI支援アプローチ

**概要:**
テストトロフィー戦略でモックを最小化し、実際の統合を重視。AI支援により効率的に実装

**メリット:**

- 実際の統合を重視し、本番環境に近い動作を保証
- モックの削減によりメンテナンス性向上
- AI支援により各種テストを効率的に作成
- スナップショットとパフォーマンステストで品質を多角的に保証

**デメリット:**

- 統合テストの実行時間がやや長い
- 初期セットアップの複雑性
- 複数のテストライブラリの学習コスト

**実装コスト:** 中  
**技術的複雑さ:** 中  
**リスク:** 低

### 選択肢B: テストピラミッド・従来型アプローチ

**概要:**
従来のテストピラミッドでユニットテストを最重視

**メリット:**

- 高速なテスト実行
- 従来の知見を活用可能
- シンプルな構成

**デメリット:**

- モック多用による実際の動作との乖離
- 統合時の問題発見が遅れる
- メンテナンスコストが高い
- AI支援の効果を十分活用できない

**実装コスト:** 低  
**技術的複雑さ:** 低  
**リスク:** 中

### 選択肢C: 最小限のテスト

**概要:**
基本的なユニットテストのみで開発速度を優先

**メリット:**

- 開発速度が最も速い
- シンプルな構成
- 学習コストが最小

**デメリット:**

- 品質リスクが高い
- バグの発見が遅れる
- リグレッションの防止が困難

**実装コスト:** 低  
**技術的複雑さ:** 低  
**リスク:** 高

### 比較表

| 観点               | 選択肢A | 選択肢B | 選択肢C | 重要度 |
| ------------------ | ------- | ------- | ------- | ------ |
| **カバレッジ達成** | 高      | 中      | 低      | 高     |
| **開発効率**       | 高      | 中      | 高      | 高     |
| **品質向上**       | 高      | 中      | 低      | 高     |
| **CI/CD統合**      | 高      | 高      | 中      | 高     |
| **メンテナンス性** | 高      | 低      | 中      | 中     |

---

## 決定

### 採用する選択肢

**選択:** 選択肢A（テストトロフィー・AI支援アプローチ）

**決定理由:**

1. 実動作の保証: 統合テスト重視により、実際の使用時の動作を確実に保証
2. メンテナンス性: モックの最小化により、テストの脆弱性を回避
3. 包括的品質: スナップショット・パフォーマンステストで多角的な品質保証

### 決定の詳細

**実装方針:**

- テストトロフィー戦略の採用
- モック最小化によるインテグレーションテスト重視
- AI支援による効率的なテスト作成

**技術的詳細:**

```yaml
# テスト構成
test_pyramid_distribution:
  unit_tests: 40% # 個別機能の正確性
  integration_tests: 30% # モジュール間連携
  e2e_tests: 10% # ユーザーシナリオ
  property_tests: 10% # エッジケース発見
  snapshot_tests: 5% # リグレッション防止
  performance_tests: 5% # パフォーマンス保証
```

**設計原則:**

- モック最小化によるリアルな動作テスト
- AI支援による効率的なテスト作成・保守
- 段階的な品質向上

---

## 結果・影響

### ポジティブな影響

**短期的効果:**

- 段階的に品質が向上し、実用的なカバレッジを達成
- AI支援によりテスト作成が容易になり開発者の生産性向上
- CI/CDパイプラインによる自動品質チェック

**長期的効果:**

- リグレッションの早期発見と防止
- 高品質なLSPサーバーによる開発体験向上
- テストコードの資産価値向上

### ネガティブな影響・トレードオフ

**受け入れるコスト:**

- 統合テスト重視による実行時間の増加
- 初期セットアップの複雑性（複数のテストライブラリ）
- AI生成テストの品質維持に継続的なレビューが必要

**リスク・課題:**

- スナップショット更新時の慎重な確認が必要
- 軽減策: 自動化されたレビュープロセスとAI支援による品質チェック

### 影響範囲

**技術的影響:**

- 全モジュールでテストトロフィー戦略を適用
- CI/CDパイプラインの複雑化
- テストインフラの整備が必要

**組織的影響:**

- AI支援テスト開発のワークフロー確立
- 品質ファーストの開発文化醸成

---

## 実装計画

### フェーズ1: テストインフラ構築

**期間:**

**実施内容:**

- [ ] cargo-llvm-cov、insta、criterionのセットアップ
- [ ] モック最小化TestServerインフラストラクチャ実装
- [ ] マトリックスCI/CDパイプライン構築
- [ ] 共通テストヘルパー・ビルダーの整備

**成功基準:**

- テストツールの正常動作確認
- CI/CDパイプラインの基本動作

### フェーズ2: テストトロフィー実装

**期間:**

**実施内容:**

- [ ] ユニットテスト（40%）- パーサー、キー抽出、翻訳ファイル処理
- [ ] 統合テスト（30%）- LSPプロトコル、実際のコンポーネント連携
- [ ] E2Eテスト（10%）- Neovim プラグインとの統合
- [ ] プロパティテスト（10%）- エッジケース発見、不変条件検証
- [ ] スナップショットテスト（5%）- LSPレスポンスフォーマット検証
- [ ] パフォーマンステスト（5%）- パーサー、キー検索のベンチマーク

**成功基準:**

- 各テスト種別の目標配分達成
- カバレッジ目標の達成（コア90%+、全体80%+）

### フェーズ3: 最適化・自動化

**期間:**

**実施内容:**

- [ ] テスト実行時間の最適化
- [ ] 自動レポート生成の設定
- [ ] ドキュメント整備

**成功基準:**

- CI実行時間10分以内
- 自動レポート生成の動作確認

---

## 監視・測定

### 成功指標

| 指標                   | 現在値 | 目標値            | 測定方法           | 責任者 |
| ---------------------- | ------ | ----------------- | ------------------ | ------ |
| 全体カバレッジ         | -      | 80%以上           | cargo-llvm-cov     | 開発者 |
| コア機能カバレッジ     | -      | 90%以上           | cargo-llvm-cov     | 開発者 |
| クリティカルパス       | -      | 95%以上           | cargo-llvm-cov     | 開発者 |
| プロパティテスト成功率 | -      | 98%以上           | proptest           | 開発者 |
| スナップショット一致率 | -      | 100%              | insta              | 開発者 |
| パフォーマンス劣化     | -      | 5%以内            | criterion          | 開発者 |
| CI実行時間             | -      | 10分以内          | GitHub Actions     | 開発者 |
| バグ検出率             | -      | リリース前90%以上 | Issue トラッキング | 開発者 |

### 監視項目

**技術メトリクス:**

- テストカバレッジ（行、分岐、機能）
- テスト実行時間
- テスト成功率
- パフォーマンス指標

**ビジネスメトリクス:**

- バグ発見率
- 開発速度（機能実装速度）
- テストメンテナンス工数

### レビュー計画

**定期レビュー:**

- 頻度: 週次
- 参加者: 開発者
- 評価項目: カバレッジ目標、テスト品質確認

**振り返りタイミング:**

- フェーズ完了時: 各フェーズの成果確認
- 機能リリース時: テスト効果測定
- 月次: カバレッジとバグ発見率の評価

---

## 学習・改善

### この決定から学んだこと

**良かった点:**

- AI支援によりテスト作成効率が大幅に向上
- テストトロフィーアプローチにより実動作の保証が強化

**改善点:**

- 初期のセットアップ工数見積もりが甘かった
- より段階的なテスト導入戦略が必要

### 他プロジェクトへの適用

**再利用可能な要素:**

- テストトロフィー戦略とAI支援の組み合わせ
- モック最小化のテストインフラ設計

**適用時の注意点:**

- プロジェクト規模に応じたテスト配分の調整
- AI支援の効果を最大化するワークフローの確立

---

## 参考資料

### 技術資料

- [cargo-llvm-cov Documentation](https://github.com/taiki-e/cargo-llvm-cov)
- [Property-based testing in Rust with Proptest](https://altsysrq.github.io/proptest-book/)
- [insta - Snapshot Testing](https://insta.rs/)
- [Criterion.rs - Statistics-driven Benchmarking](https://bheisler.github.io/criterion.rs/book/)

### 意思決定資料

- [Testing Trophy - Kent C. Dodds](https://kentcdodds.com/blog/the-testing-trophy-and-testing-classifications)
- [Language Server Protocol Specification](https://microsoft.github.io/language-server-protocol/)
- [Tower-LSP Testing Guide](https://github.com/ebkalderon/tower-lsp)

### 関連ADR

- ADR-001: i18n LSP技術スタック選定

---

**次のステップ:** ADR-001で決定した技術スタックと組み合わせて、高品質なLSPサーバーの実装を開始する。

**関連文書:**

- 実装ガイド: テストトロフィー実装ベストプラクティス（今後作成予定）
- CI/CD設定ガイド: 自動テスト環境構築手順（今後作成予定）
